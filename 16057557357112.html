<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
    优化算法 - NCDHZ
    
    </title>
    

    
    
    <link href="atom.xml" rel="alternate" title="NCDHZ" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/style.min.css">
    <link rel="stylesheet" href="asset/css/doc.css">
    <script src="asset/app.js"></script>
</head>
  <body>
    <section class="hero">
      <div class="hero-head">
          <nav class="navbar" role="navigation" aria-label="main navigation">
              <div class="container">
              <div class="navbar-brand">
                
                <a target="_self" class="navbar-item " href="https://www.majunlong.top">个人网站</a>
                
                <a target="_self" class="navbar-item " href="index.html">Home</a>
                
                <a target="_self" class="navbar-item " href="archives.html">Archives</a>
                

                <a role="button" id="navbarSNSRssSwitchBtn" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navbarSNSRssButtons">
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                  <span aria-hidden="true"></span>
                </a>
              </div>
            
              <div id="navbarSNSRssButtons" class="navbar-menu">
                <div class="navbar-start">
                  
                </div>
            
                <div class="navbar-end">
                  <div class="navbar-item">
                    <!--buttons start-->
                    <div class="buttons">
                      
                        
                        
                        
                        <a href="https://github.com/ncdhz" target="_blank" title="github">
                            <span class="icon is-large has-text-grey-darker">
                               <svg class="svg-inline--fa fa-github fa-w-16 fa-lg" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github fa-lg"></i> -->
                            </span>
                          </a>
                        
                        
                      
                      <a href="atom.xml" target="_blank" title="RSS">
                          <span class="icon is-large has-text-black-bis">
                              <svg class="svg-inline--fa fa-rss fa-w-14 fa-lg" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M128.081 415.959c0 35.369-28.672 64.041-64.041 64.041S0 451.328 0 415.959s28.672-64.041 64.041-64.041 64.04 28.673 64.04 64.041zm175.66 47.25c-8.354-154.6-132.185-278.587-286.95-286.95C7.656 175.765 0 183.105 0 192.253v48.069c0 8.415 6.49 15.472 14.887 16.018 111.832 7.284 201.473 96.702 208.772 208.772.547 8.397 7.604 14.887 16.018 14.887h48.069c9.149.001 16.489-7.655 15.995-16.79zm144.249.288C439.596 229.677 251.465 40.445 16.503 32.01 7.473 31.686 0 38.981 0 48.016v48.068c0 8.625 6.835 15.645 15.453 15.999 191.179 7.839 344.627 161.316 352.465 352.465.353 8.618 7.373 15.453 15.999 15.453h48.068c9.034-.001 16.329-7.474 16.005-16.504z"></path></svg><!-- <i class="fas fa-rss fa-lg"></i> -->
                          </span>
                      </a>
                    </div>
                    <!--buttons end-->

                  </div>
                </div>
                </div>
              </div>
            </nav>
      </div>

 <div class="hero-body ct-body"></div>
      
    </section>
    <section class="ct-body">
      <div class="container">
          <div class="columns is-variable bd-klmn-columns is-4 is-centered">
              <div class="column is-four-fifths">
                  <div class="post-body single-content">
                    
                    <h1 class="title">
                            优化算法   
                      </h1>
                     
                    
                      <div class="media">
                            
                            <figure class="media-left">
                              <p class="image is-48x48">
                                
                                  <img class="is-rounded" src="">
                                
                              </p>
                            </figure>
                            
                            <div class="media-content">
                              <div class="content">
                                <p>
                                 <span class="date">2020/11/19</span>
                                  <span class="tran-posted-in">posted in</span>&nbsp; 
                                  
                                      <span class="posted-in"><a href='%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>机器学习</a></span>
                                         
                                  

                                   
                                      
                                  <br />
                                  <span class="tran-tags">Tags:</span>&nbsp;
                                  
                                    <a class="tag is-link is-light" href='tag_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html'>#机器学习</a>
                                     

                                </p>
                              </div>
                            </div>
                         
                    </div>
                </div>
                  <article class="markdown-body single-content">
                    <h3 id="toc_0">梯度下降 (Gradient Descent)</h3>

<p>爬山的时候最陡的地方能够让你更快的到达山顶（直角三角形的直角边长度小于斜边）。而梯度下降的核心思想是：每次在当前梯度方向（最陡峭的方向）前进一步，来逼近函数的最小值（山顶）。<br/>
\[<br/>
\theta_i = \theta_{i-1} - \lambda g(\theta_{i-1})<br/>
\]</p>

<ul>
<li>\(g(\theta_{i-1})\) 所有点构成的损失函数的导数(也就是梯度)</li>
<li>\(\lambda\) 学习率，由于梯度只是一个方向，在这个方向走多远就看这个学习率了</li>
</ul>

<h3 id="toc_1">随机梯度下降（Stochastic Gradient Descent）</h3>

<p>由于梯度下降法每次计算时包含整个数据集，会影响计算的速度，而随机梯度下降(SGD)，在每一步的梯度计算上只随机选取训练集中的一个样本。</p>

<h3 id="toc_2">小批量梯度下降法 (Mini-batch-Gradient-Descent)</h3>

<p>把随机梯度下降中的一个样本改成了，一小批样本。小批量梯度下降会比随机梯度更靠近最小值。</p>

<h3 id="toc_3">动量梯度下降法 （Gradient descent with Momentum）</h3>

<p>动量梯度下降法算法就是让每一次参数更新都不仅仅取决于当前位置的梯度，还要取决于上一次上上一次的梯度，而且离当前位置越远的梯度对参数更新的影响越小。<br/>
\[<br/>
\begin{split}<br/>
d_i &amp;= \beta d_{i-1} - \lambda g(\theta_{i-1}) \\<br/>
\theta_i &amp;= \theta_{i-1} +  d_i<br/>
\end{split}<br/>
\]</p>

<h3 id="toc_4">加速梯度 ( Nesterov Accelerated Gradient)</h3>

<p>既然下一次一定会更新 \(\beta d_{i-1}\) 那么求梯度的时候就可以用提前位置的梯度 \(g(\theta_{i-1} + \beta d_{i-1})\) <br/>
\[<br/>
\begin{split}<br/>
d_i &amp;= \beta_{i-1} - \lambda g(\theta_{i-1} + \beta d_{i-1}) \\<br/>
\theta_i &amp;= \theta_{i-1} + d_i<br/>
\end{split}<br/>
\]</p>

<h2 id="toc_5">自适应梯度法</h2>

<h3 id="toc_6">Adagrad</h3>

<p>一般学习率都希望开始时大点然后后面越来越小，这样可以快速的到达最低点也能避免越过最低点（因为学习率决定了每一次向前走的距离，前面离的远可以快点走，后面离的太近了就要慢点走），而 Adagrad 就能很好的做到这点。<br/>
\[<br/>
\begin{split}<br/>
c_i &amp;= c_(i-1) + g^2(\theta_{i-1}) \\<br/>
\theta_i &amp;= \theta_{i-1} - \frac{\lambda}{\sqrt {c_i + \epsilon}} g(\theta_{i-1})<br/>
\end{split}<br/>
\]</p>

<ul>
<li>\(c_i\) 用于保存各位置梯度的平方</li>
<li>\(\epsilon\) 一般取值为\(10^{-4}\)～\(10^{-8}\)，为了防止分母取零</li>
<li>Adagrad 不需要手动调节学习率 \(\lambda\) </li>
<li>学习率 \(\frac{\lambda}{\sqrt {c_i + \epsilon}}\) 他会随着 \(c_i\) 的变大而逐步变小</li>
<li>缺点是：学习率会一直变小最后可能会导致参数无法更新</li>
</ul>

<h3 id="toc_7">Rmsprop</h3>

<p>\[<br/>
\begin{split}<br/>
c_i &amp;= \gamma c_(i-1) + (1-\gamma)g^2(\theta_{i-1}) \\<br/>
\theta_i &amp;= \theta_{i-1} - \frac{\lambda}{\sqrt {c_i + \epsilon}} g(\theta_{i-1})<br/>
\end{split}<br/>
\]<br/>
可以看出Rmsprop与Adagrad类似，只不过cache的计算略微复杂一些，使用到了一个衰减因子 \(\gamma\) </p>

<ul>
<li>衰减因子解决了Adagrad学习率迅速减小的问题</li>
<li>衰减因子\(\gamma\)通常取值为\([0.9，0.99，0.999]\)</li>
</ul>

<h3 id="toc_8">Adadelta</h3>

<p>\[<br/>
\begin{split}<br/>
c_i &amp;= \gamma c_{i-1} + (1 - \gamma) g^2(\theta_{i-1}) \\<br/>
d_i &amp;= - \frac{\sqrt{\Delta_{i-1}+\epsilon}}{\sqrt{c_i+\epsilon}}{g(\theta_{i-1})} \\<br/>
\theta_i &amp;= \theta_{i-1} + d_i \\<br/>
\Delta_i &amp;= \gamma \Delta_{i-1} + (1-\gamma)d_i^2<br/>
\end{split}<br/>
\]<br/>
Adadelta与Rmsprop类似，但是连初始的学习速率 \(\lambda\) 都不用设置</p>

<ul>
<li>学习率分子取决于 \(\gamma \Delta_{i-1} + (1-\gamma)d_i^2\) </li>
<li>\(\sqrt{\Delta_{i-1}+\epsilon}\) 中的 \(\epsilon\) 是为了避免分子为0也就是确定最开始的学习率</li>
</ul>

<h3 id="toc_9">Adam</h3>

<p>\[<br/>
\begin{split}<br/>
m_i &amp;= \beta_1 m_{i-1} + (1-\beta_1)g(\theta_{i-1}) \\<br/>
v_i &amp;= \beta_2 v_{i-1} + (1-\beta_2)g^2(\theta_{i-1}) \\<br/>
\hat{m_i} &amp;= \frac{m_i}{1-\beta_i^t} \\<br/>
\hat{v_i} &amp;= \frac{v_i}{1-\beta^t_2} \\<br/>
\theta_i &amp;= \theta_{i-1} - \frac{\lambda}{\sqrt{\hat{v_i} + \epsilon}}{\hat{m_i}}<br/>
\end{split}<br/>
\]</p>

<p>与Rmsprop类似，Adam除了利用一个衰减因子\(\beta_2\)计算cache以外，还类似Momentum，利用了上一次的参数更新方向。在参数更新的最初几步中，由于\(m_i\)与\(v_i\)是初始化为0的，为了防止最初几步的更新向0偏差，Adam利用\(\beta_i\)的\(t\)次幂来修正这种偏差（\(t\)每次更新加1）。其中，通常\(\beta_1\)取值为0.9，\(\beta_2\)取值为0.999，\(\epsilon\)取值为\(10^-8\)。</p>

                  </article>
                  <div class="comments-wrap">
                    <div class="share-comments">
                      

                      

                      
                    </div>
                  </div><!-- end comments wrap -->
              </div>
            </div><!-- end columns -->
      </div><!-- end container -->
    </section>



    <footer class="footer">
        <div class="content has-text-centered">
          <p>
              Copyright &copy; 2019
              Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
              Theme used <a target="_blank" href="https://bulma.io/">Bulma CSS</a>.
          </p>
        </div>
      </footer>



<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  















  
    




  </body>
</html>
